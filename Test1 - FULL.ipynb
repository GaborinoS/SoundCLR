{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(2048, config.class_numbers)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ProjectionModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.fc = nn.Linear(2048, 64)\n",
    "        \n",
    "        \n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.fc(x)\n",
    "\t\t\n",
    "\t\treturn x\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESC_10 = False\n",
    "ESC_50 = True\n",
    "US8K = False\n",
    "\n",
    "\n",
    "path_to_ESC50 = './data/ESC50'\n",
    "path_to_ESC10 = './data/ESC10'\n",
    "path_to_US8K = './data/US8K'\n",
    "\n",
    "path_to_classifierModel = './data/results/2020-12-22-10-42/'\n",
    "\n",
    "\n",
    "ESC10_classIds = [0, 1, 10, 11, 12, 20, 21, 38, 40, 41]\n",
    "\n",
    "\n",
    "if ESC_50:\n",
    "\tclass_numbers = 50\n",
    "else:\n",
    "\tclass_numbers = 10\n",
    "\n",
    "\n",
    "if ESC_10 or ESC_50:\n",
    "\tlr = 5e-4 #for ESC-50 and ESC-10\n",
    "\tfolds = 5\n",
    "\ttest_fold = [1]\n",
    "\ttrain_folds = list(i for i in range(1, 6) if i != test_fold[0])\t\n",
    "else:\n",
    "\tlr = 1e-4 # for US8K\n",
    "\tfold = 10\n",
    "\ttest_fold = [1]\n",
    "\ttrain_folds = list(i for i in range(1, 11) if i != test_fold[0])\t\n",
    "\t\n",
    "\n",
    "\n",
    "temperature = 0.05\n",
    "alpha = 0.5\n",
    "\n",
    "freq_masks = 2\n",
    "time_masks = 1\n",
    "freq_masks_width = 32\n",
    "time_masks_width = 32\n",
    "\n",
    "epochs = 800\n",
    "batch_size = 16\n",
    "warm_epochs = 10\n",
    "gamma = 0.98\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import librosa\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def scale(old_value, old_min, old_max, new_min, new_max):\n",
    "    old_range = (old_max - old_min)\n",
    "    new_range = (new_max - new_min)\n",
    "    new_value = (((old_value - old_min) * new_range) / old_range) + new_min\n",
    "\n",
    "    return new_value\n",
    "\n",
    "\n",
    "class ToTensor1D(tv.transforms.ToTensor):\n",
    "\n",
    "    def __call__(self, tensor: np.ndarray):\n",
    "        tensor_2d = super(ToTensor1D, self).__call__(tensor[..., np.newaxis])\n",
    "        \n",
    "        return tensor_2d.squeeze_(0)\n",
    "\n",
    "class RandomNoise():\n",
    "    def __init__(self, min_noise=0.0, max_noise=0.05): #0.002, 0.01\n",
    "        super(RandomNoise, self).__init__()\n",
    "        \n",
    "        self.min_noise = min_noise\n",
    "        self.max_noise = max_noise\n",
    "        \n",
    "    def addNoise(self, wave):\n",
    "        noise_val = random.uniform(self.min_noise, self.max_noise)\n",
    "        noise = torch.from_numpy(np.random.normal(0, noise_val, wave.shape[0]))\n",
    "        noisy_wave = wave + noise\n",
    "        \n",
    "        return noisy_wave\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.addNoise(x)\n",
    "\n",
    "\n",
    "\n",
    "class RandomScale():\n",
    "\n",
    "    def __init__(self, max_scale: float = 1.25):\n",
    "        super(RandomScale, self).__init__()\n",
    "\n",
    "        self.max_scale = max_scale\n",
    "\n",
    "    @staticmethod\n",
    "    def random_scale(max_scale: float, signal: torch.Tensor) -> torch.Tensor:\n",
    "        scaling = np.power(max_scale, np.random.uniform(-1, 1)) #between 1.25**(-1) and 1.25**(1)\n",
    "        output_size = int(signal.shape[-1] * scaling)\n",
    "        ref = torch.arange(output_size, device=signal.device, dtype=signal.dtype).div_(scaling)\n",
    "        \n",
    "        # ref1 is of size output_size\n",
    "        ref1 = ref.clone().type(torch.int64)\n",
    "        ref2 = torch.min(ref1 + 1, torch.full_like(ref1, signal.shape[-1] - 1, dtype=torch.int64))\n",
    "        \n",
    "        r = ref - ref1.type(ref.type())\n",
    "        \n",
    "        scaled_signal = signal[..., ref1] * (1 - r) + signal[..., ref2] * r\n",
    "        \n",
    "        \n",
    "        return scaled_signal\n",
    "\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.random_scale(self.max_scale, x)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class RandomCrop():\n",
    "\n",
    "    def __init__(self, out_len: int = 44100, train: bool = True):\n",
    "        super(RandomCrop, self).__init__()\n",
    "\n",
    "        self.out_len = out_len\n",
    "        self.train = train\n",
    "\n",
    "    def random_crop(self, signal: torch.Tensor) -> torch.Tensor:\n",
    "        if self.train:\n",
    "            left = np.random.randint(0, signal.shape[-1] - self.out_len)\n",
    "        else:\n",
    "            left = int(round(0.5 * (signal.shape[-1] - self.out_len)))\n",
    "\n",
    "        orig_std = signal.float().std() * 0.5\n",
    "        output = signal[..., left:left + self.out_len]\n",
    "\n",
    "        out_std = output.float().std()\n",
    "        if out_std < orig_std:\n",
    "            output = signal[..., :self.out_len]\n",
    "\n",
    "        new_out_std = output.float().std()\n",
    "        if orig_std > new_out_std > out_std:\n",
    "            output = signal[..., -self.out_len:]\n",
    "\n",
    "        return output\n",
    "\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.random_crop(x) if x.shape[-1] > self.out_len else x\n",
    "\n",
    "\n",
    "class RandomPadding():\n",
    "\n",
    "    def __init__(self, out_len: int = 88200, train: bool = True):\n",
    "        super(RandomPadding, self).__init__()\n",
    "\n",
    "        self.out_len = out_len\n",
    "        self.train = train\n",
    "\n",
    "    def random_pad(self, signal: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        if self.train:\n",
    "            left = np.random.randint(0, self.out_len - signal.shape[-1])\n",
    "        else:\n",
    "            left = int(round(0.5 * (self.out_len - signal.shape[-1])))\n",
    "\n",
    "        right = self.out_len - (left + signal.shape[-1])\n",
    "\n",
    "        pad_value_left = signal[..., 0].float().mean().to(signal.dtype)\n",
    "        pad_value_right = signal[..., -1].float().mean().to(signal.dtype)\n",
    "        output = torch.cat((\n",
    "            torch.zeros(signal.shape[:-1] + (left,), dtype=signal.dtype, device=signal.device).fill_(pad_value_left),\n",
    "            signal,\n",
    "            torch.zeros(signal.shape[:-1] + (right,), dtype=signal.dtype, device=signal.device).fill_(pad_value_right)\n",
    "        ), dim=-1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.random_pad(x) if x.shape[-1] < self.out_len else x\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "class FrequencyMask():\n",
    "    def __init__(self, max_width, numbers): \n",
    "        super(FrequencyMask, self).__init__()\n",
    "        \n",
    "        self.max_width = max_width\n",
    "        self.numbers = numbers\n",
    "    \n",
    "    def addFreqMask(self, wave):\n",
    "        #print(wave.shape)\n",
    "        for _ in range(self.numbers):\n",
    "            #choose the length of mask\n",
    "            mask_len = random.randint(0, self.max_width)\n",
    "            start = random.randint(0, wave.shape[1] - mask_len) #start of the mask\n",
    "            end = start + mask_len\n",
    "            wave[:, start:end, : ] = 0\n",
    "            \n",
    "        return wave\n",
    "    \n",
    "    def __call__(self, wave):\n",
    "        return self.addFreqMask(wave)\n",
    "    \n",
    "        \n",
    "\n",
    "class TimeMask():\n",
    "    def __init__(self, max_width, numbers): \n",
    "        super(TimeMask, self).__init__()\n",
    "        \n",
    "        self.max_width = max_width\n",
    "        self.numbers = numbers\n",
    "    \n",
    "    \n",
    "    def addTimeMask(self, wave):\n",
    "        \n",
    "        for _ in range(self.numbers):\n",
    "            #choose the length of mask\n",
    "            mask_len = random.randint(0, self.max_width)\n",
    "            start = random.randint(0, wave.shape[2] - mask_len) #start of the mask\n",
    "            end = start + mask_len\n",
    "            wave[ : , : , start:end] = 0\n",
    "            \n",
    "        return wave\n",
    "    \n",
    "    def __call__(self, wave):\n",
    "        return self.addTimeMask(wave)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class EarlyStopping:\n",
    "\t\"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\tdef __init__(self, patience=7, verbose=False, delta=0, log_path='', output_file = './results.txt'):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\tpatience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "\t\tverbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "\t\tdelta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "\t\t\"\"\"\n",
    "\t\tself.patience = patience\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.counter = 0\n",
    "\t\tself.best_score = None\n",
    "\t\tself.early_stop = False\n",
    "\t\tself.val_loss_min = np.Inf\n",
    "\t\tself.delta = delta\n",
    "\t\tself.log_path = log_path\n",
    "\t\tself.output_file = output_file\n",
    "        \n",
    "\n",
    "\tdef __call__(self, val_loss, model, epoch):\n",
    "\n",
    "\t\tscore = -val_loss\n",
    "\t\tif self.best_score is None:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model, epoch)\n",
    "\t\telif score < self.best_score - self.delta:\n",
    "\t\t\tself.counter += 1\n",
    "\t\t\tprint(f'EarlyStopping counter: {self.counter} out of {self.patience}', file=self.output_file)\n",
    "\t\t\tif self.counter >= self.patience:\n",
    "\t\t\t\tself.early_stop = True\n",
    "\t\telse:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model, epoch)\n",
    "\t\t\tself.counter = 0\n",
    "\n",
    "\tdef save_checkpoint(self, val_loss, model, epoch):\n",
    "\t\t'''Saves model when validation loss decrease.'''\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...', file=self.output_file)\n",
    "        \n",
    "\t\ttorch.save(model.state_dict(), os.path.join(self.log_path, 'checkpoint.pt'))\n",
    "\t\tself.val_loss_min = val_loss\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "class WarmUpStepLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "\n",
    "\tdef __init__(self, optimizer: torch.optim.Optimizer, cold_epochs: int, warm_epochs: int, step_size: int, \n",
    "\t\t\tgamma: float = 0.1, last_epoch: int = -1):\n",
    "\t\t\n",
    "\t\tsuper(WarmUpStepLR, self).__init__(optimizer=optimizer, last_epoch=last_epoch)\n",
    "\t\tself.cold_epochs = cold_epochs\n",
    "\t\tself.warm_epochs = warm_epochs\n",
    "\t\tself.step_size = step_size\n",
    "\t\tself.gamma = gamma\n",
    "\n",
    "\t\t\n",
    "\n",
    "\tdef get_lr(self):\n",
    "\t\tif self.last_epoch < self.cold_epochs:\n",
    "\t\t\treturn [base_lr * 0.1 for base_lr in self.base_lrs]\n",
    "\t\telif self.last_epoch < self.cold_epochs + self.warm_epochs:\n",
    "\t\t\treturn [\n",
    "\t\t\t\tbase_lr * 0.1 + (1 + self.last_epoch - self.cold_epochs) * 0.9 * base_lr / self.warm_epochs\n",
    "\t\t\t\tfor base_lr in self.base_lrs\n",
    "\t\t\t\t]\n",
    "\t\telse:\n",
    "\t\t\treturn [\n",
    "\t\t\t\tbase_lr * self.gamma ** ((self.last_epoch - self.cold_epochs - self.warm_epochs) // self.step_size)\n",
    "\t\t\t\tfor base_lr in self.base_lrs\n",
    "\t\t\t\t]\n",
    "\n",
    "\n",
    "class WarmUpExponentialLR(WarmUpStepLR):\n",
    "\n",
    "\tdef __init__(self, optimizer: torch.optim.Optimizer, cold_epochs: int, warm_epochs: int,\n",
    "                 \tgamma: float = 0.1, last_epoch: int = -1):\n",
    "\n",
    "\t\tself.cold_epochs = cold_epochs\n",
    "\t\tself.warm_epochs = warm_epochs\n",
    "\t\tself.step_size = 1\n",
    "\t\tself.gamma = gamma\n",
    "\n",
    "\t\tsuper(WarmUpStepLR, self).__init__(optimizer=optimizer, last_epoch=last_epoch)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def calculateClassInfo(class_to_representations, class_to_projections, epoch):\n",
    "\tclass_to_repMeans = {} # key is the class_id and values are mean vector for each class\n",
    "\tclass_to_projMeans = {}\n",
    "    \n",
    "\tfor class_id in class_to_representations:\n",
    "\t\tclass_to_repMeans[class_id] = torch.mean(class_to_representations[class_id], dim=0)\n",
    "\t\tclass_to_projMeans[class_id] = torch.mean(class_to_projections[class_id], dim=0)\n",
    "    \n",
    "\trep_distances = torch.zeros(50,50)\n",
    "\tproj_distances = torch.zeros(50,50)\n",
    "\tfor i in range(50):\n",
    "\t\tfor j in range(50):\n",
    "\t\t\trep_distances[i][j] = torch.dist(class_to_repMeans[i], class_to_repMeans[j])\n",
    "\t\t\tproj_distances[i][j] = torch.dist(class_to_projMeans[i], class_to_projMeans[j])\n",
    "    \n",
    "    \n",
    "\t#calculating std for each class\n",
    "\trep_std = torch.zeros(50)\n",
    "\tproj_std = torch.zeros(50)\n",
    "\tfor i in range(50):\n",
    "\t\trep_std_vec = torch.std(class_to_representations[i], dim=0)\n",
    "\t\trep_std[i] = torch.norm(rep_std_vec, p=2, dim=0)\n",
    "        \n",
    "\t\tproj_std_vec = torch.std(class_to_projections[i], dim=0)\n",
    "\t\tproj_std[i] = torch.norm(proj_std_vec, p=2, dim=0)\n",
    "    \n",
    "    \n",
    "\tfig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "\tfig.add_subplot(221)\n",
    "\tplt.title('distance between means of {} features in representation space with average of {:.4f}'.format(\n",
    "\t\tclass_to_representations[0][0].shape[0], float(rep_distances.mean())), fontsize=6)\n",
    "\tplt.imshow(rep_distances.numpy(), cmap='Blues')\n",
    "\tplt.colorbar()\n",
    "\n",
    "\tfig.add_subplot(222)\n",
    "\tplt.title('std of {} features in representation space with average of {:.4f}'.format(\n",
    "\t\tclass_to_representations[0][0].shape[0], float(rep_std.mean())), fontsize=6)\n",
    "\tplt.bar(range(50), rep_std.numpy(), 0.5 )\n",
    "    \n",
    "      \n",
    "\tfig.add_subplot(223)\n",
    "\tplt.title('distance between means of {} features in projection space with average of {:.4f}'.format(\n",
    "\t\tclass_to_projections[0][0].shape[0], float(proj_distances.mean())), fontsize=6)\n",
    "\tplt.imshow(proj_distances.numpy(), cmap='Blues')\n",
    "\tplt.colorbar()\n",
    "    \n",
    "\tfig.add_subplot(224)\n",
    "\tplt.title('std of {} features in projection spacewith average of {:.4f}'.format(\n",
    "\t\tclass_to_projections[0][0].shape[0], float(proj_std.mean())), fontsize=6)\n",
    "\tplt.bar(range(50), proj_std.numpy(), 0.5 )\n",
    "    \n",
    "    \n",
    "\tplt.savefig(fig_path + 'epoch_' + str(epoch)  + '.png', dpi=175)\n",
    "    \n",
    "\tplt.clf()\n",
    "\tplt.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m use_cuda \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available()\n\u001b[0;32m     14\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_cuda \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMyDataset\u001b[39;00m(data\u001b[39m.\u001b[39mDataset):\n\u001b[0;32m     20\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data/ESC/ESC-50-master/audio/\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import random\n",
    "import collections\n",
    "import csv\n",
    "import librosa\n",
    "\n",
    "import config\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, train=True):\n",
    "        self.root = './data/ESC/ESC-50-master/audio/'\n",
    "        self.train = train\n",
    "        \n",
    "        #getting name of all files inside the all of the train_folds\n",
    "        temp = os.listdir(self.root)\n",
    "        temp.sort()\n",
    "        self.file_names = []\n",
    "        if train:\n",
    "            for i in range(len(temp)):\n",
    "                if int(temp[i].split('-')[0]) in config.train_folds:\n",
    "                    self.file_names.append(temp[i])\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                if int(temp[i].split('-')[0]) in config.test_fold:\n",
    "                    self.file_names.append(temp[i])\n",
    "        \n",
    "        if self.train:\n",
    "            self.wave_transforms = torchvision.transforms.Compose([ transforms.ToTensor1D(), \n",
    "                                                              transforms.RandomScale(max_scale = 1.25), \n",
    "                                                              transforms.RandomPadding(out_len = 220500),\n",
    "                                                              transforms.RandomCrop(out_len = 220500)])\n",
    "             \n",
    "            \n",
    "            self.spec_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor() , \n",
    "\t\t\t\t\t\t\t\t\ttransforms.FrequencyMask(max_width = config.freq_masks_width, numbers = config.freq_masks), \n",
    "\t\t\t\t\t\t\t\t\ttransforms.TimeMask(max_width = config.time_masks_width, numbers = config.time_masks)])\n",
    "            \n",
    "        else: #for test\n",
    "            self.wave_transforms = torchvision.transforms.Compose([ transforms.ToTensor1D(),\n",
    "                                                              transforms.RandomPadding(out_len = 220500),\n",
    "                                                             transforms.RandomCrop(out_len = 220500)])\n",
    "        \n",
    "            self.spec_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor() ])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.file_names[index ]  \n",
    "        path = self.root + file_name\n",
    "        wave, rate = librosa.load(path, sr=44100)\n",
    "        \n",
    "        #identifying the label of the sample from its name\n",
    "        temp = file_name.split('.')[0]\n",
    "        class_id = int(temp.split('-')[-1])\n",
    "        \n",
    "        if wave.ndim == 1:\n",
    "            wave = wave[:, np.newaxis]\n",
    "\t\t\n",
    "\t# normalizing waves to [-1, 1]\n",
    "        if np.abs(wave.max()) > 1.0:\n",
    "            wave = transforms.scale(wave, wave.min(), wave.max(), -1.0, 1.0)\n",
    "        wave = wave.T * 32768.0\n",
    "        \n",
    "        # Remove silent sections\n",
    "        start = wave.nonzero()[1].min()\n",
    "        end = wave.nonzero()[1].max()\n",
    "        wave = wave[:, start: end + 1]  \n",
    "        \n",
    "        wave_copy = np.copy(wave)\n",
    "        wave_copy = self.wave_transforms(wave_copy)\n",
    "        wave_copy.squeeze_(0)\n",
    "        \n",
    "        s = librosa.feature.melspectrogram(wave_copy.numpy(), sr=44100, n_mels=128, n_fft=1024, hop_length=512) \n",
    "        log_s = librosa.power_to_db(s, ref=np.max)\n",
    "        \n",
    "\t# masking the spectrograms\n",
    "        log_s = self.spec_transforms(log_s)\n",
    "        \n",
    "        \n",
    "        #creating 3 channels by copying log_s1 3 times \n",
    "        spec = torch.cat((log_s, log_s, log_s), dim=0)\n",
    "        \n",
    "        return file_name, spec, class_id\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def create_generators():\n",
    "    train_dataset = MyDataset(train=True)\n",
    "    test_dataset = MyDataset(train=False)\n",
    "    \n",
    "\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size = config.batch_size, shuffle=True, num_workers=10 ,drop_last=False)\n",
    "    \n",
    "    test_loader = data.DataLoader(test_dataset, batch_size = config.batch_size, shuffle=True, num_workers=10 ,drop_last=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./results/2023-09_crossEntropyLoss/classifier already exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Update the model loading line\n",
    "model = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "model.fc = nn.Sequential(nn.Identity())\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0])\n",
    "model = model.to(device)\n",
    "\n",
    "classifier = model_classifier.Classifier().to(device)\n",
    "\n",
    "train_loader, val_loader = dataset.create_generators()\n",
    "\n",
    "root = './results/'\n",
    "main_path = root + str(datetime.datetime.now().strftime('%Y-%m')) + \"_crossEntropyLoss\"\n",
    "if not os.path.exists(main_path):\n",
    "    os.mkdir(main_path)\n",
    "\n",
    "classifier_path = main_path + '/' + 'classifier'\n",
    "\n",
    "# Modify the code that creates directories to handle existing directories\n",
    "if not os.path.exists(classifier_path):\n",
    "    os.mkdir(classifier_path)\n",
    "else:\n",
    "    print(f\"Directory {classifier_path} already exists.\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(classifier.parameters()),\n",
    "                             lr=config.lr, weight_decay=1e-3)\n",
    "\n",
    "scheduler = WarmUpExponentialLR(optimizer, cold_epochs=0, warm_epochs=config.warm_epochs, gamma=config.gamma)\n",
    "\n",
    "\n",
    "def hotEncoder(v):\n",
    "    ret_vec = torch.zeros(v.shape[0], config.class_numbers).to(device)\n",
    "    for s in range(v.shape[0]):\n",
    "        ret_vec[s][v[s]] = 1\n",
    "    return ret_vec\n",
    "\n",
    "def cross_entropy_one_hot(input, target):\n",
    "    _, labels = target.max(dim=1)\n",
    "    return nn.CrossEntropyLoss(weight=class_weights)(input, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "config.ESC_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########################################################################################\n",
    "#create class weight vector with the length of number of classes with 0\n",
    "class_weights = torch.ones(config.class_numbers).to(device)\n",
    "\n",
    "main_model = model.module if hasattr(model, 'module') else model\n",
    "###########################################################################################\n",
    "\n",
    "def train_crossEntropy():\n",
    "\tnum_epochs = 800\n",
    "\twith open(main_path + '/results.txt','w', 1) as output_file:\n",
    "\t\tmainModel_stopping = EarlyStopping(patience=300, verbose=True, log_path=main_path, output_file=output_file)\n",
    "\t\tclassifier_stopping = EarlyStopping(patience=300, verbose=False, log_path=classifier_path, output_file=output_file)\n",
    "\n",
    "\t\tprint('*****', file=output_file)\n",
    "\t\tprint('BASELINE', file=output_file)\n",
    "\t\tprint('transfer - augmentation on both waves and specs - 3 channels', file=output_file)\n",
    "\t\tif config.ESC_10:\n",
    "\t\t\tprint('ESC_10', file=output_file)\n",
    "\t\t\tprint('train folds are {} and test fold is {}'.format(config.train_folds, config.test_fold), file=output_file)\n",
    "\t\telif config.ESC_50:\n",
    "\t\t\tprint('ESC_50', file=output_file)\n",
    "\t\t\tprint('train folds are {} and test fold is {}'.format(config.train_folds, config.test_fold), file=output_file)\n",
    "\t\telif config.US8K:\n",
    "\t\t\tprint('US8K', file=output_file)\n",
    "\t\t\tprint('train folds are {} and test fold is {}'.format(config.us8k_train_folds, config.us8k_test_fold), file=output_file)\n",
    "\n",
    "\n",
    "\t\tprint('number of freq masks are {} and their max length is {}'.format(config.freq_masks, config.freq_masks_width), file=output_file)\n",
    "\t\tprint('number of time masks are {} and their max length is {}'.format(config.time_masks, config.time_masks_width), file=output_file)\n",
    "\t\tprint('*****', file=output_file)\n",
    "\t\n",
    "\n",
    "\n",
    "\t\tfor epoch in range(num_epochs):\n",
    "\t\t\tmodel.train()\n",
    "\t\t\tclassifier.train()\n",
    "        \n",
    "\t\t\ttrain_loss = []\n",
    "\t\t\ttrain_corrects = 0\n",
    "\t\t\ttrain_samples_count = 0\n",
    "        \n",
    "\t\t\tfor _, x, label in train_loader:\n",
    "\t\t\t\tloss = 0\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "            \n",
    "\t\t\t\tinp = x.float().to(device)\n",
    "\t\t\t\tlabel = label.to(device).unsqueeze(1)\n",
    "\t\t\t\tlabel_vec = hotEncoder(label)\n",
    "            \n",
    "\t\t\t\ty_rep = model(inp)\n",
    "\t\t\t\ty_rep = F.normalize(y_rep, dim=0)\n",
    "            \n",
    "\t\t\t\ty_pred = classifier(y_rep)\n",
    "            \n",
    "\t\t\t\tloss += cross_entropy_one_hot(y_pred, label_vec)\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\ttrain_loss.append(loss.item() )\n",
    "\t\t\t\toptimizer.step()\n",
    "            \n",
    "\t\t\t\ttrain_corrects += (torch.argmax(y_pred, dim=1) == torch.argmax(label_vec, dim=1)).sum().item()\n",
    "\t\t\t\ttrain_samples_count += x.shape[0]\n",
    "        \n",
    "        \n",
    "\t\t\tval_loss = []\n",
    "\t\t\tval_corrects = 0\n",
    "\t\t\tval_samples_count = 0\n",
    "        \n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tclassifier.eval()\n",
    "        \n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tfor _, val_x, val_label in val_loader:\n",
    "\t\t\t\t\tinp = val_x.float().to(device)\n",
    "\t\t\t\t\tlabel = val_label.to(device)\n",
    "\t\t\t\t\tlabel_vec = hotEncoder(label)\n",
    "                \n",
    "\t\t\t\t\ty_rep = model(inp)\n",
    "\t\t\t\t\ty_rep = F.normalize(y_rep, dim=0)\n",
    "\n",
    "\t\t\t\t\ty_pred = classifier(y_rep)\n",
    "                \n",
    "\t\t\t\t\ttemp = cross_entropy_one_hot(y_pred, label_vec)\n",
    "\t\t\t\t\tval_loss.append(temp.item() )\n",
    "                \n",
    "\t\t\t\t\tval_corrects += (torch.argmax(y_pred, dim=1) == torch.argmax(label_vec, dim=1)).sum().item() \n",
    "\t\t\t\t\tval_samples_count += val_x.shape[0]\n",
    "        \n",
    "\t\t\n",
    "        \n",
    "\t\t\tscheduler.step()\n",
    "        \n",
    "\t\t\ttrain_acc = train_corrects / train_samples_count\n",
    "\t\t\tval_acc = val_corrects / val_samples_count\n",
    "\t\t\tprint('\\n', file=output_file)\n",
    "\t\t\tprint(\"Epoch: {}/{}...\".format(epoch+1, num_epochs), \"Loss: {:.4f}...\".format(np.mean(train_loss)),\n",
    "\t\t\t\t\"Val Loss: {:.4f}\".format(np.mean(val_loss)), file=output_file)\n",
    "\t\t\tprint('train_acc is {:.4f} and val_acc is {:.4f}'.format(train_acc, val_acc), file=output_file)\n",
    "\t\t\tmainModel_stopping(-val_acc, main_model, epoch+1)\n",
    "\t\t\tclassifier_stopping(-val_acc, classifier, epoch+1)\n",
    "\t\t\tif mainModel_stopping.early_stop:\n",
    "\t\t\t\tprint(\"Early stopping\", file=output_file)\n",
    "\t\t\t\treturn\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\ttrain_crossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the instantiation of the classifier object\n",
    "#classifier = Classifier().to(device) # Ensure Classifier class is defined before this line\n",
    "\n",
    "# Get the main model from the DataParallel module\n",
    "main_model = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "# Load the checkpoints\n",
    "main_model.load_state_dict(torch.load('results/2023-09_crossEntropyLoss10_f/checkpoint.pt'))\n",
    "classifier.load_state_dict(torch.load('results/2023-09_crossEntropyLoss10_f/classifier/checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.25%\n",
      "Precision: 89.29%\n",
      "Recall: 86.25%\n",
      "F1-score: 86.07%\n",
      "Confusion Matrix:\n",
      "[[8 0 0 0 0 0 0 0 0 0]\n",
      " [1 6 0 0 0 1 0 0 0 0]\n",
      " [0 0 5 3 0 0 0 0 0 0]\n",
      " [0 0 0 8 0 0 0 0 0 0]\n",
      " [0 0 0 0 8 0 0 0 0 0]\n",
      " [0 0 0 0 0 8 0 0 0 0]\n",
      " [0 0 0 0 0 0 8 0 0 0]\n",
      " [0 0 0 0 0 1 0 7 0 0]\n",
      " [0 0 3 1 0 0 0 0 4 0]\n",
      " [0 0 0 1 0 0 0 0 0 7]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize variables to store the true and predicted labels\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for _, x, label in val_loader:\n",
    "        inp = x.float().to(device)\n",
    "        label = label.to(device).unsqueeze(1)\n",
    "        label_vec = hotEncoder(label)\n",
    "        \n",
    "        y_rep = main_model(inp)\n",
    "        y_rep = F.normalize(y_rep, dim=0)\n",
    "\n",
    "        y_pred = classifier(y_rep)\n",
    "        \n",
    "        true_labels.extend(label.squeeze(1).cpu().numpy())\n",
    "        pred_labels.extend(torch.argmax(y_pred, dim=1).cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_preds = sum(t == p for t, p in zip(true_labels, pred_labels))\n",
    "accuracy = correct_preds / len(true_labels)\n",
    "\n",
    "# Calculate precision, recall, F1-score, and support\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1-score: {f1_score * 100:.2f}%\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset_ESC10' from 'c:\\\\Users\\\\Gabriel\\\\OneDrive\\\\Dokumente\\\\GitHub\\\\SoundCLR\\\\dataset_ESC10.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
